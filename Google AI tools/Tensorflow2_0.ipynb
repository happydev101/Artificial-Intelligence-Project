{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensorflow2.0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hluJuY2fzXl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install tensorflow==2.0.0-beta1bb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFl5YPkwf933",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e9584700-0c43-43e6-f1c1-cd59ba327d21"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, optimizers, Sequential, metrics\n",
        "\n",
        "(xs, ys),_ = datasets.mnist.load_data()\n",
        "\n",
        "xs = tf.convert_to_tensor(xs, dtype=tf.float32) / 255.\n",
        "db = tf.data.Dataset.from_tensor_slices((xs,ys))\n",
        "db = db.batch(32).repeat(10)\n",
        "\n",
        "\n",
        "model = Sequential([layers.Dense(128, activation='relu'),\n",
        "                     layers.Dense(256, activation='relu'),\n",
        "                     layers.Dense(128, activation='relu'),\n",
        "                     layers.Dense(10)])\n",
        "model.build(input_shape=(None, 28*28))\n",
        "model.summary()\n",
        "\n",
        "optimizer = optimizers.SGD(lr=0.01)\n",
        "acc_meter = metrics.Accuracy()\n",
        "\n",
        "for step, (x,y) in enumerate(db):\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        x = tf.reshape(x, (-1, 28*28))\n",
        "        out = model(x)\n",
        "        y_onehot = tf.one_hot(y, depth=10)\n",
        "        loss = tf.square(out-y_onehot)\n",
        "        loss = tf.reduce_sum(loss) / 32\n",
        "\n",
        "\n",
        "    acc_meter.update_state(tf.argmax(out, axis=1), y)\n",
        "\n",
        "    grads = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "    if step % 400==0:\n",
        "        print('Loss:', float(loss), ', Acc:', acc_meter.result().numpy())\n",
        "        acc_meter.reset_states()\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              multiple                  100480    \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              multiple                  33024     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              multiple                  32896     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              multiple                  1290      \n",
            "=================================================================\n",
            "Total params: 167,690\n",
            "Trainable params: 167,690\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Loss: 1.4258075952529907 , Acc: 0.0625\n",
            "Loss: 0.38807275891304016 , Acc: 0.72429687\n",
            "Loss: 0.2507108449935913 , Acc: 0.86609375\n",
            "Loss: 0.2694101929664612 , Acc: 0.8934375\n",
            "Loss: 0.2381736785173416 , Acc: 0.90851563\n",
            "Loss: 0.2331923246383667 , Acc: 0.93125\n",
            "Loss: 0.23998084664344788 , Acc: 0.9236719\n",
            "Loss: 0.13050329685211182 , Acc: 0.9320313\n",
            "Loss: 0.1644153743982315 , Acc: 0.9311719\n",
            "Loss: 0.13408735394477844 , Acc: 0.9321875\n",
            "Loss: 0.20943939685821533 , Acc: 0.9479687\n",
            "Loss: 0.15194492042064667 , Acc: 0.9378125\n",
            "Loss: 0.1336594521999359 , Acc: 0.94210935\n",
            "Loss: 0.25659626722335815 , Acc: 0.9423438\n",
            "Loss: 0.08575120568275452 , Acc: 0.9496094\n",
            "Loss: 0.1137005165219307 , Acc: 0.9501563\n",
            "Loss: 0.10603661090135574 , Acc: 0.94640625\n",
            "Loss: 0.09624090045690536 , Acc: 0.95085937\n",
            "Loss: 0.28829002380371094 , Acc: 0.946875\n",
            "Loss: 0.17882254719734192 , Acc: 0.9592969\n",
            "Loss: 0.16550388932228088 , Acc: 0.9517969\n",
            "Loss: 0.07983575761318207 , Acc: 0.9557812\n",
            "Loss: 0.1340770274400711 , Acc: 0.95539063\n",
            "Loss: 0.06445540487766266 , Acc: 0.9516406\n",
            "Loss: 0.18231931328773499 , Acc: 0.9634375\n",
            "Loss: 0.15264646708965302 , Acc: 0.9561719\n",
            "Loss: 0.13875970244407654 , Acc: 0.95734376\n",
            "Loss: 0.16579441726207733 , Acc: 0.9596875\n",
            "Loss: 0.09208379685878754 , Acc: 0.959375\n",
            "Loss: 0.1515907645225525 , Acc: 0.96421874\n",
            "Loss: 0.08745626360177994 , Acc: 0.9603906\n",
            "Loss: 0.12412647157907486 , Acc: 0.9621094\n",
            "Loss: 0.09318651258945465 , Acc: 0.9579688\n",
            "Loss: 0.17597216367721558 , Acc: 0.9669531\n",
            "Loss: 0.10445526242256165 , Acc: 0.964375\n",
            "Loss: 0.05835988000035286 , Acc: 0.96375\n",
            "Loss: 0.09207600355148315 , Acc: 0.9646094\n",
            "Loss: 0.06632769107818604 , Acc: 0.9599219\n",
            "Loss: 0.09098213911056519 , Acc: 0.97132814\n",
            "Loss: 0.089759960770607 , Acc: 0.964375\n",
            "Loss: 0.12547528743743896 , Acc: 0.9657813\n",
            "Loss: 0.07230783998966217 , Acc: 0.96703124\n",
            "Loss: 0.0770251452922821 , Acc: 0.9644531\n",
            "Loss: 0.033031027764081955 , Acc: 0.97\n",
            "Loss: 0.09663895517587662 , Acc: 0.966875\n",
            "Loss: 0.07107262313365936 , Acc: 0.9690625\n",
            "Loss: 0.06888598203659058 , Acc: 0.9660938\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}