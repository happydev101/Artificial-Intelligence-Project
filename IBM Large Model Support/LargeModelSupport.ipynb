{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LargeModelSupport.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uglRSP5CjGHd",
        "colab_type": "text"
      },
      "source": [
        "# Large Model Support: Keras Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fE0Fn65Bkugi",
        "colab_type": "text"
      },
      "source": [
        "Additional Resourcers:\n",
        "- https://www.ibm.com/support/knowledgecenter/en/SS5SF7_1.6.0/navigation/pai_getstarted_tflmsv2.html\n",
        "- https://github.com/IBM/tensorflow-large-model-support\n",
        "- https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
        "- https://stackoverflow.com/questions/46493419/use-a-generator-for-keras-model-fit-generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pEBfX1sjM21",
        "colab_type": "text"
      },
      "source": [
        "## Downloading necessary dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlDFlEoXXmPq",
        "colab_type": "code",
        "outputId": "fad9da8f-107d-4a54-cc2c-165bec52b992",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "source": [
        "! git clone https://github.com/IBM/tensorflow-large-model-support.git\n",
        "! pip install ./tensorflow-large-model-support"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'tensorflow-large-model-support' already exists and is not an empty directory.\n",
            "Processing ./tensorflow-large-model-support\n",
            "Requirement already satisfied: tensorflow-gpu>=1.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-large-model-support==0.1.0) (1.14.0)\n",
            "Requirement already satisfied: toposort>=1.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-large-model-support==0.1.0) (1.5)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=1.5->tensorflow-large-model-support==0.1.0) (1.14.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=1.5->tensorflow-large-model-support==0.1.0) (0.7.1)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=1.5->tensorflow-large-model-support==0.1.0) (1.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=1.5->tensorflow-large-model-support==0.1.0) (1.11.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=1.5->tensorflow-large-model-support==0.1.0) (1.0.8)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=1.5->tensorflow-large-model-support==0.1.0) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=1.5->tensorflow-large-model-support==0.1.0) (1.12.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=1.5->tensorflow-large-model-support==0.1.0) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=1.5->tensorflow-large-model-support==0.1.0) (3.7.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=1.5->tensorflow-large-model-support==0.1.0) (0.2.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=1.5->tensorflow-large-model-support==0.1.0) (0.33.4)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=1.5->tensorflow-large-model-support==0.1.0) (0.8.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=1.5->tensorflow-large-model-support==0.1.0) (0.1.7)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=1.5->tensorflow-large-model-support==0.1.0) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=1.5->tensorflow-large-model-support==0.1.0) (1.16.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu>=1.5->tensorflow-large-model-support==0.1.0) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu>=1.5->tensorflow-large-model-support==0.1.0) (0.15.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu>=1.5->tensorflow-large-model-support==0.1.0) (41.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu>=1.5->tensorflow-large-model-support==0.1.0) (2.8.0)\n",
            "Building wheels for collected packages: tensorflow-large-model-support\n",
            "  Building wheel for tensorflow-large-model-support (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/00/30/9f/af0877bd7f5dab704d0eacfd5a954c020d3783fc9b07e23542\n",
            "Successfully built tensorflow-large-model-support\n",
            "Installing collected packages: tensorflow-large-model-support\n",
            "  Found existing installation: tensorflow-large-model-support 0.1.0\n",
            "    Uninstalling tensorflow-large-model-support-0.1.0:\n",
            "      Successfully uninstalled tensorflow-large-model-support-0.1.0\n",
            "Successfully installed tensorflow-large-model-support-0.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorflow_large_model_support"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvxX5pgCgDsf",
        "colab_type": "code",
        "outputId": "620adb52-05f4-4d8d-f58c-6b10ff7f078a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "! pip install memory_profiler"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: memory_profiler in /usr/local/lib/python3.6/dist-packages (0.55.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from memory_profiler) (5.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAIVGRtxjVa2",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPz-nPBpX1-z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow_large_model_support import LMSKerasCallback\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "from keras.utils import np_utils\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import preprocessing\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten, Reshape\n",
        "from keras.layers.convolutional import Convolution1D, Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6c8yzh4ff4t1",
        "colab_type": "code",
        "outputId": "9f1f9a27-1f2c-4161-a8a6-fcb71be8910c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%load_ext memory_profiler \n",
        "# Used to examining memory usage"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The memory_profiler extension is already loaded. To reload it, use:\n",
            "  %reload_ext memory_profiler\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_U1PbtMLYjjQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LMSKerasCallback and LMS share a set of keyword arguments. Here we just\n",
        "# use the default options.\n",
        "lms_callback = LMSKerasCallback()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mO4l1Qm7o2gA",
        "colab_type": "code",
        "outputId": "e33a4e4a-61f8-4a72-bd8f-cbdd2c5dc6c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Creating a linearly separable dataset using Gaussian Distributions.\n",
        "# The first half of the number in Y is 0 and the other half 1.\n",
        "# Therefore I made the first half of the two features quite different from\n",
        "# the second half of the features (setting the value of the means quite \n",
        "# similar) so that make quite simple the classification between the \n",
        "# classes (the data is linearly separable).\n",
        "dataset_len = 2000000\n",
        "dlen = int(dataset_len/2)\n",
        "X_11 = pd.Series(np.random.normal(2,2,dlen))\n",
        "X_12 = pd.Series(np.random.normal(9,2,dlen))\n",
        "X_1 = pd.concat([X_11, X_12]).reset_index(drop=True)\n",
        "X_21 = pd.Series(np.random.normal(1,3,dlen))\n",
        "X_22 = pd.Series(np.random.normal(7,3,dlen))\n",
        "X_2 = pd.concat([X_21, X_22]).reset_index(drop=True)\n",
        "X_31 = pd.Series(np.random.normal(3,1,dlen))\n",
        "X_32 = pd.Series(np.random.normal(3,4,dlen))\n",
        "X_3 = pd.concat([X_31, X_32]).reset_index(drop=True)\n",
        "Y = pd.Series(np.repeat([0,1],dlen))\n",
        "df = pd.concat([X_1, X_2, X_3, Y], axis=1)\n",
        "df.columns = ['X1', 'X2', 'X3', 'Y']\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X1</th>\n",
              "      <th>X2</th>\n",
              "      <th>X3</th>\n",
              "      <th>Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.975025</td>\n",
              "      <td>3.634938</td>\n",
              "      <td>3.784286</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.901440</td>\n",
              "      <td>4.542160</td>\n",
              "      <td>2.406820</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.954707</td>\n",
              "      <td>2.570255</td>\n",
              "      <td>1.763635</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6.044522</td>\n",
              "      <td>1.149320</td>\n",
              "      <td>2.940318</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.754139</td>\n",
              "      <td>6.806385</td>\n",
              "      <td>3.548091</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         X1        X2        X3  Y\n",
              "0  0.975025  3.634938  3.784286  0\n",
              "1  0.901440  4.542160  2.406820  0\n",
              "2  0.954707  2.570255  1.763635  0\n",
              "3  6.044522  1.149320  2.940318  0\n",
              "4 -0.754139  6.806385  3.548091  0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-OGf0Ajo4uJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df.drop(['Y'], axis = 1).values\n",
        "y = df['Y']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ecSyyitpZaa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preproces(df, X, y, train_size = 0.80):\n",
        "  # label_encoder object knows how to understand word labels. \n",
        "  label_encoder = preprocessing.LabelEncoder() \n",
        "\n",
        "  # Encode labels\n",
        "  y = label_encoder.fit_transform(y) \n",
        "\n",
        "  # identify shape and indices\n",
        "  num_rows, num_columns = df.shape\n",
        "  delim_index = int(num_rows * train_size)\n",
        "\n",
        "  # Splitting the dataset in training and test sets\n",
        "  X_train, y_train = X[:delim_index, :], y[:delim_index]\n",
        "  X_test, y_test = X[delim_index:, :], y[delim_index:]\n",
        "\n",
        "  # Checking sets dimensions\n",
        "  print('X_train dimensions: ', X_train.shape, 'y_train: ', y_train.shape)\n",
        "  print('X_test dimensions:', X_test.shape, 'y_validation: ', y_test.shape)\n",
        "\n",
        "  # Checking dimensions in percentages\n",
        "  total = X_train.shape[0] + X_test.shape[0]\n",
        "  print('X_train Percentage:', (X_train.shape[0]/total)*100, '%')\n",
        "  print('X_test Percentage:', (X_test.shape[0]/total)*100, '%')\n",
        "  \n",
        "  return X_train, y_train, X_test, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12RyCmXEpaxa",
        "colab_type": "code",
        "outputId": "c45d3731-d6f3-4f79-da2d-721c5ef4b39d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "X_train, y_train, X_test, y_test = preproces(df, X, y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train dimensions:  (1600000, 3) y_train:  (1600000,)\n",
            "X_test dimensions: (400000, 3) y_validation:  (400000,)\n",
            "X_train Percentage: 80.0 %\n",
            "X_test Percentage: 20.0 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVJXaf_Vjcha",
        "colab_type": "text"
      },
      "source": [
        "## Machine Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfABliZLpKaQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(12, activation='relu', input_dim=df.shape[1]-1))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
        "\n",
        "batch_size = 8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XDryHsTjiYT",
        "colab_type": "text"
      },
      "source": [
        "### Large Model Support"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpaj1Udoe6Yv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generator(X_data, y_data, batch_size):\n",
        "\n",
        "  samples_per_epoch = X_data.shape[0]\n",
        "  number_of_batches = samples_per_epoch/batch_size\n",
        "  counter=0\n",
        "\n",
        "  while 1:\n",
        "\n",
        "    X_batch = np.array(X_data[batch_size*counter:batch_size*(counter+1)]).astype('float32')\n",
        "    y_batch = np.array(y_data[batch_size*counter:batch_size*(counter+1)]).astype('float32')\n",
        "    counter += 1\n",
        "    yield X_batch,y_batch\n",
        "\n",
        "    #restart counter to yeild data in the next epoch as well\n",
        "    if counter >= number_of_batches:\n",
        "        counter = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTmp--hkpL14",
        "colab_type": "code",
        "outputId": "60a89d62-e8f3-4a45-dff1-3bafb007f032",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "%%memit\n",
        "\n",
        "model.fit_generator(generator(X_train, y_train,batch_size), epochs=2,steps_per_epoch = X_train.shape[0]/batch_size, callbacks=[lms_callback])\n",
        "\n",
        "# Peak Memory = Memory usage of the Python interpreter after that line has been executed. Increment = represents the difference in memory of the current line with respect to the last one. "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "200000/200000 [==============================] - 601s 3ms/step - loss: 0.0222 - acc: 0.9984\n",
            "Epoch 2/2\n",
            "200000/200000 [==============================] - 596s 3ms/step - loss: 0.0203 - acc: 0.9984\n",
            "peak memory: 2834.80 MiB, increment: 2.88 MiB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICXEFgxZJw2O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LMS_preds = model.predict_classes(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKuVDfQP1EqT",
        "colab_type": "code",
        "outputId": "91bf3104-243e-4a9f-c2ca-83ee1d296801",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "LMS_acc = accuracy_score(y_test, LMS_preds)\n",
        "print(\"Model accuracy using Large Model Support:\", LMS_acc*100, '%')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model accuracy using Large Model Support: 99.9995 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvsu1zy0jmlo",
        "colab_type": "text"
      },
      "source": [
        "### Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChfGmZHurESR",
        "colab_type": "code",
        "outputId": "178139fc-9237-47e0-acb6-c471ef7428d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "%%memit\n",
        "#without generator\n",
        "model.fit(x = np.array(X_train), y = np.array(y_train), batch_size = batch_size, epochs = 2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "1600000/1600000 [==============================] - 537s 336us/step - loss: 0.0449 - acc: 0.9846\n",
            "Epoch 2/2\n",
            "1600000/1600000 [==============================] - 538s 336us/step - loss: 0.0403 - acc: 0.9857\n",
            "peak memory: 2862.26 MiB, increment: 26.15 MiB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGTomTytz4EC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = model.predict_classes(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEM_cQwT0qk7",
        "colab_type": "code",
        "outputId": "bfd57ef8-c001-480d-c4c5-2cdffb986d42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sk_pred = np.round(preds)\n",
        "sk_acc = accuracy_score(y_test, sk_pred)\n",
        "print(\"Model accuracy using Sklearn:\", sk_acc*100, '%')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model accuracy using Sklearn: 98.4795 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}